{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object-Based Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides insights into the workflow of Object-Based Augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from utils.loading import load_masked_images, load_images, load_labels\n",
    "from utils.visualization import plot_image, plot_masked_image\n",
    "from utils.normalize import normalize\n",
    "import json\n",
    "from utils.visualization import plot_prediction\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_img = '/data/train_images/train_0.tif'\n",
    "example_img = example_img.replace('/notebooks', '')\n",
    "#example_img = example_img.replace('INF367A-Solafune/', '')\n",
    "print(\"Updated path:\", example_img)\n",
    "\n",
    "plot_image(example_img, band=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from augmentation import augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = images[\"train_0.tif\"][\"image\"]\n",
    "# mask = processed_masked_images[\"train_0.tif\"][\"image\"]\n",
    "\n",
    "# augmented = augment(img, mask, 0.1, 1)\n",
    "# augmented_image = augmented[\"image\"]\n",
    "# augmented_mask = augmented[\"mask\"]\n",
    "\n",
    "# original_image = images[\"train_0.tif\"][\"image\"] \n",
    "# original_mask = processed_masked_images[\"train_0.tif\"][\"image\"]\n",
    "# print(original_image.shape, original_mask.shape)\n",
    "# print(augmented_image.shape, augmented_mask.shape)\n",
    "# # visualisering med kun ett bilde, ikke alle\n",
    "# i=10\n",
    "# print(augmented_image[i].shape, augmented_mask[i].shape)\n",
    "# visualize(augmented_image[i], augmented_mask[i], original_image[i], original_mask[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size, classes, num_channels\n",
    "#generator = individual_object_functions.Generator(10, \"none\", \"plantation\", \"logging\", \"mining\", \"grassland_shrubland\", 12)\n",
    "# angle = 90\n",
    "# img = images[\"train_0.tif\"][\"image\"]\n",
    "# mask = processed_masked_images[\"train_0.tif\"][\"image\"]\n",
    "# rotated_img = individual_object_functions.rotate(img.transpose(2, 1, 0), angle).transpose(2, 1, 0)\n",
    "# rotated_mask = individual_object_functions.rotate(mask.transpose(2, 1, 0), angle).transpose(2, 1, 0)\n",
    "# i = 0\n",
    "# visualize(image=rotated_img[i], mask=rotated_mask[i], original_image=img[i], original_mask=mask[i])\n",
    "# (1024, 1024, 12)\n",
    "# (12, 1024, 1024) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = generator.read_json(\"data\")\n",
    "# \"\"\"\n",
    "# lagrer dataen som en dict data_images med en liste med alle bildene\n",
    "# hvert bilde indexeres med nummer og har keys: filename, annotations og startend date\n",
    "# \"\"\"\n",
    "# len(labels[\"data_images\"]) # 176\n",
    "# labels[\"data_images\"][0].keys() # dict_keys(['file_name', 'annotations', 'startend_date_composite'])\n",
    "# labels[\"data_images\"][0][\"startend_date_composite\"] # '2019/01/01_2020/12/31'\n",
    "# labels[\"data_images\"][0][\"file_name\"] # 'train_0.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num = 1998\n",
    "# cropped_object, object_mask = new_generator._crop_target_object(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.OBA import object_based_augmentation\n",
    "new_generator = object_based_augmentation.Generator(batch_size=10, subset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_generator.augm = True\n",
    "\n",
    "new_generator.augm_prob = 1\n",
    "new_generator.geometric_augm_prob = 1\n",
    "new_generator.color_augm_prob = 0\n",
    "\n",
    "new_generator.object_augm = True\n",
    "new_generator.object_augm_prob = 1\n",
    "\n",
    "new_generator.background_augm_prob = 0\n",
    "\n",
    "new_generator.shadows = False\n",
    "\n",
    "new_generator.extra_objects = 5\n",
    "\n",
    "# not currently integrated\n",
    "new_generator.extra_background_prob = 0\n",
    "\n",
    "image, mask = new_generator.generate_augmented_sample()\n",
    "print(\"Result:\")\n",
    "new_generator.visualize(image[5], mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    new_generator.visualize(image[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.OBA import object_based_augmentation\n",
    "dataset = object_based_augmentation.create_OBA_dataset(\n",
    "    prob_of_OBA=0.3, \n",
    "    subset=True,\n",
    "    augm=True, \n",
    "    object_augm=True, \n",
    "    extra_background_prob=0, # not implemented\n",
    "    background_augm_prob=0.6,\n",
    "    shadows=False, # not usefull\n",
    "    extra_objects=3,\n",
    "    object_augm_prob=1,\n",
    "    augm_prob=1,\n",
    "    geometric_augm_prob=1,\n",
    "    color_augm_prob=1,\n",
    "    batch_size=1,\n",
    "    min_area=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some images have too large mask and therefore does not open for any objects to be added as no objects may overlap. This could be ignored, but qould require further processing for a correct mask. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INF367A",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
