{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (TBD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from utils.loading import load_masked_images, load_images, load_labels\n",
    "from utils.visualization import plot_image\n",
    "from utils.normalize import normalize\n",
    "\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = load_labels()\n",
    "images = load_images(subset=True)\n",
    "masked_images = load_masked_images(subset=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image = \"train_0.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of labels:\", len(labels))\n",
    "print(\"Keys for labels:\", list(labels.keys())[:5], end=\"\\n\\n\")\n",
    "\n",
    "print(f\"Example of labels for {example_image} with {len(labels[example_image])} polygons:\")    \n",
    "for label in labels[example_image]:\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Keys for images:\",images[example_image].keys(), end=\"\\n\\n\") \n",
    "print(f\"Profile for {example_image}:\")\n",
    "print(images[example_image][\"profile\"],end=\"\\n\\n\")\n",
    "print(f\"Image for {example_image}:\")\n",
    "print(images[example_image][\"image\"],end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masked images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Keys for masked_images:\",masked_images[example_image].keys(), end=\"\\n\\n\") \n",
    "print(f\"Profile for masked {example_image}:\")\n",
    "print(masked_images[example_image][\"profile\"],end=\"\\n\\n\")\n",
    "print(f\"Masked image for masked {example_image}:\")\n",
    "print(masked_images[example_image][\"image\"],end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "values = images[example_image][\"image\"] # The first band\n",
    "print(\"Shape of an image:\", values.shape)\n",
    "\n",
    "found_nan = list()\n",
    "for img in images:\n",
    "    for i in range(12):\n",
    "        values = images[img][\"image\"][i]\n",
    "        if np.isnan(values).any():\n",
    "            found_nan.append(img)\n",
    "            break\n",
    "\n",
    "print(f\"Found {len(found_nan)} images with NaN values: {found_nan}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But does all bands of one image with NaN values all have the same Nan values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_nan = list()\n",
    "for img in found_nan:\n",
    "    nan_mask = np.isnan(images[img][\"image\"][0])\n",
    "    for i in range(1, 12):\n",
    "        nan_mask &= np.isnan(images[img][\"image\"][i])\n",
    "\n",
    "    if not nan_mask.any():\n",
    "        different_nan.append(img)\n",
    "\n",
    "print(f\"Found {len(different_nan)} with different NaN values per band: {different_nan}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently not. We wanted to look at the NaN values, but this was found to be diffuclt (most of the time) or impossible, as they are most likely too insignificant to be seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for img in found_nan:\n",
    "    if count == 5:\n",
    "        break\n",
    "    plot_image(img, num_plots=3)\n",
    "    plot_image(img, num_plots=3, no_nan=True)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is difficult to see the difference between including and excluding nan, but we found it to be necessary to remove all nan value before normalizing the image. If we did not remove the nan value, the values of mean and std ended up as nan values. Looking at image train_0.tif, the nan values are visible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at a datapoints profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images[example_image][\"profile\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing a data point\n",
    "\n",
    "We have already visualized the data point, but let's take a closer look at one specific data point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,9,3):\n",
    "    # First 6 images including the polygon\n",
    "    plot_image(example_image, num_plots=1, band=i)\n",
    "    # Last 6 images excluding the polygon\n",
    "    plot_image(example_image, num_plots=1, band=i, polygons=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we visualize the locations on a map? (does it exist tools to do this already?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_tensor = torch.tensor([images[img][\"image\"] for img in images])\n",
    "image_tensor = torch.nan_to_num(image_tensor, nan=0.0)  # As images inludes NaN values, we replace them with 0.0\n",
    "print(\"Shape:\", image_tensor.shape, end=\"\\n\\n\")\n",
    "\n",
    "normalized_image_tensor = normalize(image_tensor)\n",
    "\n",
    "print(\"Before normalization:\", image_tensor[0][0][0])\n",
    "print(\"After normalization:\", normalized_image_tensor[0][0][0], end=\"\\n\\n\")\n",
    "\n",
    "plot_image(example_image, num_plots=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = True\n",
    "x_train_dict = load_images(subset)\n",
    "y_train_dict = load_masked_images(subset)\n",
    "\n",
    "x_train = [torch.tensor(each['image']) for each in x_train_dict.values()]\n",
    "y_train = [torch.tensor(each['image']) for each in y_train_dict.values()]\n",
    "\n",
    "x_train_tensor = torch.stack(x_train, dim=0)  # Shape: [num_samples, 12, 1024, 1024]\n",
    "y_train_tensor = torch.stack(y_train, dim=0).squeeze(1).long()   # Shape: [num_samples, 1, 1024, 1024]\n",
    "\n",
    "x_train_tensor = torch.nan_to_num(x_train_tensor, nan=0.0)\n",
    "x_train_tensor = normalize(x_train_tensor)\n",
    "\n",
    "train_loader = TensorDataset(x_train_tensor, y_train_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many polygons can one training point have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon_counts = {}\n",
    "for img_name in images.keys():\n",
    "    if img_name in labels:\n",
    "        polygon_counts[img_name] = len(labels[img_name])\n",
    "    else:\n",
    "        polygon_counts[img_name] = 0\n",
    "    \n",
    "polygon_counts = dict(sorted(polygon_counts.items(), key=lambda x: int(x[0].split('_')[1].split('.')[0])))\n",
    "\n",
    "count = 0\n",
    "for img_name, count in polygon_counts.items():\n",
    "    if count == 10:\n",
    "        break\n",
    "    print(f\"{img_name}: {count} polygons\")\n",
    "\n",
    "## Image with the most polygons\n",
    "max_polygons = max(polygon_counts, key=polygon_counts.get)\n",
    "print()\n",
    "print(f\"Image with the most polygons: {max_polygons} with {polygon_counts[max_polygons]} polygons\")\n",
    "\n",
    "plot_image(max_polygons, num_plots=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Er det likt distribuert?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INF367A",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
